import cv2
import numpy as np
import os
import mediapipe as mp
import tkinter as tk
from tkinter import simpledialog

# Configurar MediaPipe para manos con mejor precisi√≥n
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False, 
    max_num_hands=2, 
    min_detection_confidence=0.7,  # Mayor precisi√≥n
    min_tracking_confidence=0.7    # Mejor seguimiento
)
mp_draw = mp.solutions.drawing_utils

# Inicializar Tkinter para di√°logos
root = tk.Tk()
root.withdraw()  # Ocultar la ventana principal

# Crear directorio para guardar los datos
DATA_DIR = 'data'
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# Funci√≥n para capturar nueva se√±a
def capture_new_sign():
    # Pedir el nombre de la se√±a
    sign = simpledialog.askstring("Nueva Se√±a", "¬øQu√© se√±a vas a realizar?")
    if not sign:
        return None
    # Limpiar el nombre de la se√±a
    sign = sign.lower().replace(" ", "_")
    return sign

# === FUNCI√ìN MEJORADA PARA EXTRAER COORDENADAS ===
def extract_best_hand_landmarks(multi_hand_landmarks, handedness_results):
    """Extrae coordenadas de la mejor mano detectada de manera consistente"""
    if not multi_hand_landmarks:
        return [0.0] * 63
    
    hands_data = []
    
    # Recopilar informaci√≥n de todas las manos
    if handedness_results and handedness_results.multi_handedness:
        for hand_landmarks, handedness in zip(multi_hand_landmarks, handedness_results.multi_handedness):
            coords = []
            for lm in hand_landmarks.landmark:
                coords.extend([lm.x, lm.y, lm.z])
            
            confidence = handedness.classification[0].score
            hand_label = handedness.classification[0].label
            
            hands_data.append({
                'coords': coords,
                'confidence': confidence,
                'label': hand_label
            })
    else:
        # Si no hay informaci√≥n de handedness, usar la primera mano
        coords = []
        for lm in multi_hand_landmarks[0].landmark:
            coords.extend([lm.x, lm.y, lm.z])
        return coords
    
    if len(hands_data) == 1:
        return hands_data[0]['coords']
    elif len(hands_data) == 2:
        # Usar la mano de mayor confianza de manera consistente
        best_hand = max(hands_data, key=lambda x: x['confidence'])
        return best_hand['coords']
    else:
        return hands_data[0]['coords']

# Configuraci√≥n inicial mejorada
num_sequences = 40  # M√°s secuencias para mejor entrenamiento
sequence_length = 30  # Frames por secuencia
min_confidence = 0.7  # Confianza m√≠nima para guardar frame
cap = cv2.VideoCapture(0)

print("üöÄ Sistema de Recolecci√≥n de Datos para Lenguaje de Se√±as")
print("üìã Instrucciones:")
print("   - Haz cada se√±a de forma clara y consistente")
print("   - Mant√©n las manos visibles en todo momento") 
print("   - Cada se√±a se grabar√° en 40 secuencias de 30 frames")
print("   - ESC para cancelar secuencia actual")
print("   - Q para pasar a la siguiente se√±a")

while True:
    # Preguntar si quiere agregar una nueva se√±a o salir
    sign = capture_new_sign()
    if not sign:
        break

    # Crear directorio para cada se√±a
    sign_dir = os.path.join(DATA_DIR, sign)
    if not os.path.exists(sign_dir):
        os.makedirs(sign_dir)

    print(f'\nüéØ Preparando recolecci√≥n para: "{sign}"')
    print('üí° Posiciona tus manos y presiona "Q" para comenzar')

    # Fase de preparaci√≥n
    ready = False
    while not ready:
        ret, frame = cap.read()
        if not ret:
            continue
            
        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb_frame)
        
        # Mostrar preview
        if results.multi_hand_landmarks:
            num_hands = len(results.multi_hand_landmarks)
            for hand_landmarks in results.multi_hand_landmarks:
                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        else:
            num_hands = 0
            
        cv2.putText(frame, f'üéØ Preparado para: {sign.upper()}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f'üëê Manos detectadas: {num_hands}', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(frame, 'Presiona Q para empezar a grabar', (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
        cv2.putText(frame, 'ESC para cancelar esta se√±a', (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        cv2.imshow('ü§ü Recolecci√≥n de Datos - SignLanguage', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            ready = True
        elif key == 27:  # ESC
            print(f"‚ùå Cancelada recolecci√≥n para '{sign}'")
            break
    
    if not ready:
        continue

    for sequence in range(num_sequences):
        frame_data = []
        frames_captured = 0
        frames_skipped = 0
        
        print(f'\nüé¨ Iniciando secuencia {sequence + 1}/{num_sequences} para "{sign}"')
        print('üí° Mant√©n la se√±a estable y clara durante 3-4 segundos')
        
        while len(frame_data) < sequence_length:
            ret, frame = cap.read()
            if not ret:
                continue
                
            # Voltear la imagen horizontalmente para vista tipo espejo
            frame = cv2.flip(frame, 1)
            h, w, c = frame.shape
            
            # Convertir a RGB para MediaPipe
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb_frame.flags.writeable = False
            results = hands.process(rgb_frame)
            rgb_frame.flags.writeable = True
            
            # Extraer coordenadas usando la funci√≥n mejorada
            hand_coords = extract_best_hand_landmarks(results.multi_hand_landmarks, results)
            
            # Verificar si hay datos v√°lidos (no todos ceros)
            has_valid_data = any(coord != 0.0 for coord in hand_coords)
            
            if has_valid_data and results.multi_hand_landmarks:
                frame_data.append(hand_coords)
                frames_captured += 1
                status_color = (0, 255, 0)  # Verde para frame v√°lido
                status_text = f"‚úÖ Frame {len(frame_data)}/{sequence_length}"
            else:
                frames_skipped += 1
                status_color = (0, 0, 255)  # Rojo para frame inv√°lido
                status_text = f"‚ùå Sin mano detectada ({frames_skipped} omitidos)"
            
            # Dibujar todas las manos detectadas
            num_hands = 0
            if results.multi_hand_landmarks:
                num_hands = len(results.multi_hand_landmarks)
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            
            # Mostrar informaci√≥n detallada
            cv2.putText(frame, f'üéØ Se√±a: {sign.upper()}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            cv2.putText(frame, f'üìä Secuencia: {sequence + 1}/{num_sequences}', (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(frame, status_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
            cv2.putText(frame, f'üëê Manos: {num_hands}', (10, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            cv2.putText(frame, f'‚úÖ V√°lidos: {frames_captured} | ‚ùå Omitidos: {frames_skipped}', (10, h-40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            cv2.putText(frame, 'ESC=Cancelar secuencia | Q=Siguiente se√±a', (10, h-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            
            cv2.imshow('ü§ü Recolecci√≥n de Datos - SignLanguage', frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC para cancelar secuencia
                print(f"‚ö†Ô∏è Secuencia {sequence} cancelada")
                break
            elif key == ord('q'):  # Q para terminar esta se√±a
                break

        # Guardar los datos recolectados solo si tenemos suficientes frames
        if len(frame_data) >= sequence_length:
            # Asegurar que tenemos exactamente sequence_length frames
            frame_data = frame_data[:sequence_length]
            npy_path = os.path.join(sign_dir, f'seq_{sequence}.npy')
            np.save(npy_path, frame_data)
            print(f'‚úÖ Secuencia {sequence + 1} guardada: {frames_captured} frames v√°lidos')
        else:
            print(f'‚ùå Secuencia {sequence + 1} descartada: solo {len(frame_data)} frames v√°lidos')

    print(f'\nüéâ Recolecci√≥n completada para "{sign}": {num_sequences} secuencias')

cap.release()
cv2.destroyAllWindows()

